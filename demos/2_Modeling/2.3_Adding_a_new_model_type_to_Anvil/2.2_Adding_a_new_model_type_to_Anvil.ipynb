{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c50a52c",
   "metadata": {},
   "source": [
    "# 2.2 Adding a new model type to Anvil\n",
    "<div style=\"text-align: center\">\n",
    "<img src=\"anvil_diagram.png\" alt=\"Anvil diagram\" width=\"500\"/>  \n",
    "</div>\n",
    "\n",
    "### Background\n",
    "When we work with model types at OpenADMET, we aim to implement them in our main training harness, Anvil, which we then use to mass produce models across datasets. This makes training and comparing models very easy, and selecting the highest performing model types more simple.  \n",
    "\n",
    "Our anvil harness is implemented in the [openadmet-models repo](https://github.com/OpenADMET/openadmet-models) (possibly subject to change) along with all of the model wrappers and comparison code.  \n",
    "Generally at OpenADMET, we don’t have a mandate to develop our own model architectures from scratch, rather to compare and tweak extant model architectures, making adjustments where it is well supported by evidence.  \n",
    "\n",
    "#### What we mean by model \"type\"\n",
    "Broadly, we mean an algorithm that takes input features and converts them to some kind of representation that can then be used to predict on new data.  \n",
    "\n",
    "Model types can basically be thought of as having two components\n",
    "\n",
    "- **Features**\n",
    "- **Architecture / Algorithm**\n",
    "\n",
    "| Type A - sklearn | Type B - neural network |\n",
    "|----------|----------|\n",
    "| For type A model types, you can select from a number of prebuilt features (e.g descriptors, molecular fingerprints, SMILES strings as text) and feed them into an array of pre-built machine learning algorithms (e.g XGBoost gradient boosted trees, SVM, Ridge Regression). Models of this kind often support a scikit-learn style interface. The first important step of implementing a model architecture is recognizing that each of these subsections maps to a class that is pulled from a registry (more detail later). | For type B model types, the features and the model architecture are far more linked. This is often the case for neural networks such as GNNs, GINs, etc, where you need to feed in a molecular graph to the top of the algorithm. Additionally for neural networks, technical choices matter more as a various model implementations require data to be pushed through the NN library in which the architecture is implemented (e.g PyTorch). |\n",
    "\n",
    "#### Type A - sklearn\n",
    "In our anvil infrastructure, this is captured in the recipe YAML file in the procedure section. Here, we combine some features (RDKit 2D descriptors) with a TabPFN classifier model.\n",
    "```yaml\n",
    "procedure:\n",
    "  split:\n",
    "...\n",
    "\n",
    "  feat:\n",
    "    type: DescriptorFeaturizer\n",
    "    params:\n",
    "      descr_type: \"desc2d\"\n",
    "\n",
    "  model:\n",
    "    type: TabPFNClassifierModel\n",
    "    params:\n",
    "      ignore_pretraining_limits: True\n",
    "      device: cpu\n",
    "\n",
    "  train:\n",
    "    type: SKLearnBasicTrainer\n",
    "```\n",
    "\n",
    "#### Type B - neural network\n",
    "Alternatively for a Type B  or NN model, e.g ChemProp (chemprop) we would use the below. This is a pytorch model, so we use a featurizer that computes graphs and stores them in a pytorch dataloader. We then have a wrapper around the NN architecture that can be trained using pytorch lightning.\n",
    "```yaml\n",
    "procedure:\n",
    "\n",
    "  split:\n",
    "...\n",
    "  feat:\n",
    "    type: ChemPropFeaturizer\n",
    "\n",
    "\n",
    "  model:\n",
    "    type: ChemPropSingleTaskRegressorModel\n",
    "\n",
    "  train:\n",
    "    type: LightningTrainer\n",
    "    params:\n",
    "      max_epochs: 1\n",
    "      accelerator: \"cpu\"\n",
    "      use_wandb: false\n",
    "      wandb_project: \"openadmet-testing\"\n",
    "```\n",
    "### Requirements\n",
    "- Familiarity with the Anvil workflow, see the [2.1_training_models_with_Anvil](./2.1_Training_models_with_Anvil/) demo.\n",
    "- You should have the `openadmet-models` repo in an IDE or coding tool of your choice.\n",
    "## 1. Overview\n",
    "There's no real code demo in this notebook. Instead, we aim to walkthrough some guidelines on how you can research models and correctly implement into Anvil for easy use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daa65e7",
   "metadata": {},
   "source": [
    "## 2. Research models\n",
    "1. Find a new model architecture and learn more about it:\n",
    "    1. Does it have a reference implementation? \n",
    "    2. Does it have solid community support? \n",
    "    3. How easy is it to use? \n",
    "    4. How well established?\n",
    "2. Decide if your model is **Type A or Type B** that is trainable through sckit-learn or pytorch. This should be reasonably obvious from looking at the reference implementation. \n",
    "    1. What kind of input features does it expect? See the relevant sections below.\n",
    "\n",
    "## 3. Implement features (if needed)\n",
    "#### Type A models\n",
    "Traditional ML and scikit learn compatible models generally work with most input feature sets, e.g Descriptors, fingerprints, precomputed vectors from pretraining etc. However you should check to see what kind of input features are recommended for your model and see if they are implemented in openadmet/models/features. If not, you should implement them!  \n",
    "\n",
    "The API for an example featurizer is shown below:\n",
    "```python\n",
    "from openadmet.models.features.feature_base import featurizers, FeatureBase\n",
    "\n",
    "@featurizers.register(\"MyFeaturizer\")\n",
    "class MyFeaturizer(FeatureBase):\n",
    "    \"\"\"\n",
    "    Fingerprint featurizer for molecules, relies on molfeat backend\n",
    "    \"\"\"\n",
    "\n",
    "    def featurize(self, smiles: Iterable[str]) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Featurize a list of SMILES strings\n",
    "        \"\"\"\n",
    "        .... # compute your features\n",
    "        return feat, indices\n",
    "```\n",
    "\n",
    "\n",
    "#### Type B models\n",
    "Pytorch compatible models are a little bit more complicated. This is because you need to map between the normal machine learning representation and a setup that can be trained easily using pytorch.  \n",
    "\n",
    "For a neural network you need to transform your data into a Pytorch dataloader which can then be consumed by the Pytorch lightning model framework.  \n",
    "\n",
    "A Featurizer for Chemprop is shown below. Note that somewhat similar to the Type A models, a dataloader and successful indices are returned along with additional scaler (can be none for no scaling) and raw Pytorch Dataset.\n",
    "```python\n",
    "@featurizers.register(\"ChemPropFeaturizer\")\n",
    "class ChemPropFeaturizer(DeepLearningFeaturizer):\n",
    "    \"\"\"\n",
    "    ChemPropFeaturizer featurizer for molecules, relies on chemprop\n",
    "    \"\"\"\n",
    "\n",
    "    normalize_targets: bool = True\n",
    "    n_jobs: int = 4\n",
    "    batch_size: int = 128\n",
    "    shuffle: bool = False\n",
    "\n",
    "    def _prepare(self):\n",
    "        \"\"\"\n",
    "        Prepare the featurizer\n",
    "        \"\"\" \n",
    "    \n",
    "    def featurize(\n",
    "        self, smiles: Iterable[str], y: Iterable[Any] = None\n",
    "    ) -> tuple[\n",
    "        DataLoader,\n",
    "        np.ndarray,\n",
    "        StandardScaler,\n",
    "        Union[MoleculeDataset, ReactionDataset, MulticomponentDataset],\n",
    "    ]:\n",
    "        \"\"\"\n",
    "        Featurize a list of SMILES strings\n",
    "\n",
    "        #TODO: we likely want to separate the scaling from the featurization\n",
    "        \"\"\"\n",
    "        if y is not None:\n",
    "            # if a pandas dataframe or series\n",
    "            if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "                y = y.to_numpy()\n",
    "            y = y.reshape(-1, 1) if y.ndim == 1 else y\n",
    "\n",
    "            dataset = MoleculeDataset(\n",
    "                [MoleculeDatapoint.from_smi(smi, y_) for smi, y_ in zip(smiles, y)]\n",
    "            )\n",
    "            if self.normalize_targets:\n",
    "                scaler = dataset.normalize_targets()\n",
    "            else:\n",
    "                scaler = None\n",
    "        else:\n",
    "            dataset = MoleculeDataset(\n",
    "                [MoleculeDatapoint.from_smi(smi) for smi in smiles]\n",
    "            )\n",
    "            scaler = None\n",
    "\n",
    "        dataloader = self.dataset_to_dataloader(\n",
    "            dataset,\n",
    "            num_workers=self.n_jobs,\n",
    "            shuffle=self.shuffle,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "        # Need to also return an index of the original input for which the features were computed\n",
    "        indices = np.arange(len(smiles))\n",
    "\n",
    "        return dataloader, indices, scaler, dataset\n",
    "```\n",
    "A few points to note: \n",
    "\n",
    "- You need to compute your feature matrix from the input iterable (in this case SMILES, but could be anything)\n",
    "- You should compute for the whole length array, returning a feature matrix\n",
    "- You can use multiprocessing inside the featurizer; the indices return variable is a mask saying which featurization worked.\n",
    "- You need to register your featurizer by adding the `register` decorator and importing the python file in `openadmet/models/registries.py`\n",
    "\n",
    "## 4. Implement model wrapper\n",
    "Implement your model wrapper in openadmet/models/architecture/my_model.py. If the model doesn’t have an external reference implementation, you can bake the logic into this class.  \n",
    "The three key API touch points are:  \n",
    "1. **`build`:** Construct the internal representation of the model such that it is ready fro training\n",
    "2. **`predict`:** Predict using a trained model \n",
    "3. **`train`:** Train the model directly (often better to use a **Trainer**)\n",
    "The API looks like the below.  \n",
    "```python\n",
    "from openadmet.models.architecture.model_base import PickleableModelBase, models\n",
    "from my_model_reference_implementation import MyRefModel \n",
    "\n",
    "@models.register(\"MyModel\")\n",
    "class MyModel(PickleableModelBase):\n",
    "    \"\"\"\n",
    "\t\tMyModel\n",
    "    \"\"\"\n",
    "\t\n",
    "    type: ClassVar[str]\n",
    "    mod_class = MyRefModel\n",
    "\t\toption1: blah\n",
    "\t\toption2: blah\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_params(cls, class_params: dict = {}, mod_params: dict = {}):\n",
    "        \"\"\"\n",
    "        Create a model from parameters\n",
    "        \"\"\"\n",
    "\n",
    "        instance = cls(**class_params, mod_params=mod_params)\n",
    "        instance.build()\n",
    "        return instance\n",
    "\n",
    "\n",
    "    def train(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        self.build()\n",
    "        self.estimator = self.estimator.fit(X, y)\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Prepare the model\n",
    "        \"\"\"\n",
    "        if not self.estimator:\n",
    "            self.estimator = self.mod_class(option1=self.option1, option2=self.option2)\n",
    "        else:\n",
    "            logger.warning(\"Model already exists, skipping build\")\n",
    "\n",
    "    def predict(self, X: np.ndarray, **kwargs) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict using the model\n",
    "        \"\"\"\n",
    "        if not self.estimator:\n",
    "            raise ValueError(\"Model not trained\")\n",
    "        return np.expand_dims(self.estimator.predict(X), axis=1)\n",
    "```\n",
    "\n",
    "**Like with the featurizer, you have to register the classes and import in registries.py**\n",
    "\n",
    "## 5. Testing implementation\n",
    "You should first test things are working the way you expect by doing some anvil runs with the new setup you want.  Some of the recipes in [`openadmet/models/tests/test_data`](/openadmet/models/tests/test_data/) should serve as good examples. See the [Training a model with Anvil](/demos/2.1_Training_models_with_Anvil/) with anvil on how to do that easily. Then, write and test with an anvil recipe that chains together all of the classes you want to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415ca9a",
   "metadata": {},
   "source": [
    "✨✨✨✨✨✨✨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
