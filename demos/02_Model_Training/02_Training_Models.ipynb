{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84fb9470",
   "metadata": {},
   "source": [
    "# 2.0 Model Training\n",
    "<div style=\"text-align: center\">\n",
    "<img src=\"static/anvil_diagram.png\" alt=\"Anvil diagram\" width=\"500\"/>  \n",
    "</div>\n",
    "\n",
    "## How the Anvil Infrastructure Works\n",
    "\n",
    "Anvil is our primary infrastructure for model training and evaluation, built to support scalable, reproducible, and rigorous development of ADMET prediction models.  \n",
    "\n",
    "Recognizing that building the best models requires training many variants, ensuring their reproducibility, and enabling robust performance comparisons, Anvil centers around a YAML-based recipe system.  \n",
    "\n",
    "These recipes allow users to specify model architectures and training procedures in a standardized, shareable format—minimizing code duplication while supporting both deep learning and traditional machine learning approaches.  \n",
    "\n",
    "Designed with both internal and external engagement in mind, Anvil aims to lower the barrier for outside users to adopt and fine-tune models by offering simple, transparent workflows. Long-term, it will serve as a foundation for broader community involvement and model reuse.\n",
    "\n",
    "### Requirements\n",
    "To run Anvil, you need:\n",
    "1. A dataset that has been processed with `01_Curate_ChEMBL_Data.ipynb`.  \n",
    "2. A `YAML` file with instructions for Anvil. We will show you how to create this file in this notebook.\n",
    "\n",
    "## Training a Model to Predict CYP3A4 Inhibition\n",
    "\n",
    "Now that we have a cleaned a dataset, we can train a model to predict **CYP3A4 inhibition**.  \n",
    "\n",
    "This notebook will walk you through how to run the Anvil model training workflow with the CYP3A4 data processed and cleaned in previous notebooks.\n",
    "\n",
    "## Creating the YAML file\n",
    "The heart of an anvil run is in its `YAML` configuration file. Here we specify nearly everything needed to:\n",
    "- load data\n",
    "- preprocess it\n",
    "- split the data appropriately into train/validation/test\n",
    "- featurize according to model selection\n",
    "- train the model\n",
    "- and, finally, validate on the test set (which generates performance metrics and plots)  \n",
    "\n",
    "We will walkthrough two `YAML` files: one for training a traditional machine learning model (`anvil_lgbm.yaml`) and one for training a deep learning model (`anvil_chemprop.yaml`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e7a193",
   "metadata": {},
   "source": [
    "## Training a Traditional Machine Learning model: LightGBM \n",
    "\n",
    "Here is a `YAML` file for training a LightGBM (LGBM) model. We are using the previously curated PXR data from ChEMBL. Be sure to read through the comments (in green) to understand each field.  \n",
    "\n",
    "1. At a minimum, ensure `resource`, `input_col`, and `target_cols` are specified to match your dataset, as these will vary per dataset\n",
    "2. The `procedure` section may not need much modification, especially if not tweaking parameters, but look it over to make sure it’s sensible\n",
    "\n",
    "```yaml \n",
    "# This spection specifies the input data\n",
    "data:\n",
    "  # Specify the dataset file\n",
    "  resource: ../../01_Data_Curation/processed_data/processed_CYP3A4_inhibition.csv\n",
    "  type: intake\n",
    "  input_col: OPENADMET_CANONICAL_SMILES\n",
    "  # Specify each (1+) of the target columns, or the column that you're trying to predict\n",
    "  target_cols:\n",
    "  - OPENADMET_LOGAC50\n",
    "  dropna: true\n",
    "\n",
    "# Additional metadata\n",
    "metadata:\n",
    "  authors: Your Name\n",
    "  email: youremail@email.com\n",
    "  biotargets:\n",
    "  - CYP3A4\n",
    "  build_number: 0\n",
    "  description: basic regression using a LightGBM model\n",
    "  driver: sklearn\n",
    "  name: lgbm_pchembl\n",
    "  tag: openadmet-chembl\n",
    "  tags:\n",
    "  - openadmet\n",
    "  - test\n",
    "  - pchembl\n",
    "  version: v1\n",
    "\n",
    "# Section specifying training procedure\n",
    "procedure:\n",
    "# Featurization specification\n",
    "  feat:\n",
    "    # Using concatenated features, which combines multiple featurizers\n",
    "    # here we use DescriptorFeaturizer and FingerprintFeaturizer for 2D RDKit descriptors and ECFP4 fingerprints\n",
    "    # See openadmet.models.features \n",
    "    type: FeatureConcatenator\n",
    "    # Add parameters for the featurizer. Full description of the featurizer options are in Section 5.\n",
    "    params:\n",
    "      featurizers:\n",
    "        DescriptorFeaturizer:\n",
    "          descr_type: \"desc2d\"\n",
    "        FingerprintFeaturizer:\n",
    "          fp_type: \"ecfp:4\"\n",
    "  \n",
    "  # Model specification\n",
    "  model:\n",
    "    # Indicate model type\n",
    "    # See openadmet.models.architecture for all model types\n",
    "    type: LGBMRegressorModel\n",
    "    # Specify model parameters\n",
    "    params:\n",
    "      alpha: 0.005\n",
    "      learning_rate: 0.05\n",
    "      n_estimators: 500\n",
    "\n",
    "\n",
    "  # Specify data splits\n",
    "  split:\n",
    "    # Specify how data will be split\n",
    "    # See openadmet.models.split\n",
    "    type: ShuffleSplitter\n",
    "    # Specify split parameters\n",
    "    params:\n",
    "      random_state: 42\n",
    "      train_size: 0.8\n",
    "      val_size: 0.0 # For LGBM, no validation set is needed\n",
    "      test_size: 0.2 # If you want to compare tree-based models with Dl models later, the test sizes should match\n",
    "    \n",
    "  # Specify training configuration\n",
    "  train:\n",
    "    # Specify the trainer, here SKLearnBasicTrainer as model has an sklearn interface\n",
    "    # could also use SKLearnGridSearchTrainer for hyperparameter tuning\n",
    "    type: SKLearnBasicTrainer\n",
    "\n",
    "\n",
    "# Section specifying report generation\n",
    "report:\n",
    "  # Configure evaluation\n",
    "  eval:\n",
    "  # Generate regression metrics\n",
    "  - type: RegressionMetrics\n",
    "    params: {}\n",
    "  # Generate regression plots & do cross validation\n",
    "  - type: SKLearnRepeatedKFoldCrossValidation\n",
    "    params:\n",
    "      axes_labels:\n",
    "      - True pAC50\n",
    "      - Predicted pAC50\n",
    "      max_val: 10\n",
    "      min_val: 3\n",
    "      pXC50: true\n",
    "      n_splits: 5\n",
    "      n_repeats: 5\n",
    "      title: True vs Predicted pAC50 on test set\n",
    "\n",
    "```\n",
    "\n",
    "After you have created or modified this `YAML` file to your liking, you can run the workflow with the below command either in a `bash` cell or in your command line:\n",
    "```\n",
    "  openadmet anvil --recipe-path <your_file.yaml> --output-dir <output folder name>\n",
    "```\n",
    "\n",
    "This may take 5-10 minutes to run, depending on the number of epochs, your hyperparameters (e.g. learning rate), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb012b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: cd: demos/02_Model_Training: No such file or directory\n",
      "/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/bin/openadmet\", line 3, in <module>\n",
      "    from openadmet.models.cli.cli import cli\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/openadmet/models/cli/cli.py\", line 5, in <module>\n",
      "    from openadmet.models.cli.anvil import anvil\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/openadmet/models/cli/anvil.py\", line 5, in <module>\n",
      "    from openadmet.models.anvil.specification import AnvilSpecification\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/openadmet/models/anvil/specification.py\", line 22, in <module>\n",
      "    from openadmet.models.registries import *  # noqa: F401, F403\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/openadmet/models/registries.py\", line 20, in <module>\n",
      "    from openadmet.models.architecture.tabpfn import *  # noqa: F401 F403\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/openadmet/models/architecture/tabpfn.py\", line 9, in <module>\n",
      "    from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import (\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/tabpfn_extensions/__init__.py\", line 37, in <module>\n",
      "    opt_in()\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/interactive/flows.py\", line 137, in opt_in\n",
      "    if not _trigger_prompts(delta_days, max_prompts):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/interactive/flows.py\", line 69, in _trigger_prompts\n",
      "    config = download_config()\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/tabpfn_common_utils/utils.py\", line 96, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/config.py\", line 44, in download_config\n",
      "    resp = requests.get(url, params=params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/requests/api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/requests/adapters.py\", line 644, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 534, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/site-packages/urllib3/connection.py\", line 565, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/http/client.py\", line 1430, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/http/client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/http/client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/socket.py\", line 720, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/ssl.py\", line 1251, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cynthiaxu/miniforge3/envs/demos/lib/python3.12/ssl.py\", line 1103, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "%d format: a real number is required, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbash\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexport OADMET_NO_RICH_LOGGING=1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mcd demos/02_Model_Training\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mopenadmet anvil --recipe-path anvil_lgbm.yaml --output-dir lgbm\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/site-packages/IPython/core/magics/script.py:160\u001b[39m, in \u001b[36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[39m\u001b[34m(line, cell)\u001b[39m\n\u001b[32m    159\u001b[39m     line = script\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/site-packages/IPython/core/magics/script.py:339\u001b[39m, in \u001b[36mScriptMagics.shebang\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.raise_error:\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(p.returncode, cell) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31m<class 'str'>\u001b[39m: (<class 'TypeError'>, TypeError('%d format: a real number is required, not NoneType'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2205\u001b[39m, in \u001b[36mInteractiveShell.showtraceback\u001b[39m\u001b[34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[39m\n\u001b[32m   2202\u001b[39m         traceback.print_exc()\n\u001b[32m   2203\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2205\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call_pdb:\n\u001b[32m   2207\u001b[39m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[32m   2208\u001b[39m     \u001b[38;5;28mself\u001b[39m.debugger(force=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/site-packages/ipykernel/zmqshell.py:587\u001b[39m, in \u001b[36mZMQInteractiveShell._showtraceback\u001b[39m\u001b[34m(self, etype, evalue, stb)\u001b[39m\n\u001b[32m    581\u001b[39m sys.stdout.flush()\n\u001b[32m    582\u001b[39m sys.stderr.flush()\n\u001b[32m    584\u001b[39m exc_content = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtraceback\u001b[39m\u001b[33m\"\u001b[39m: stb,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mename\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype.\u001b[34m__name__\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mevalue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    588\u001b[39m }\n\u001b[32m    590\u001b[39m dh = \u001b[38;5;28mself\u001b[39m.displayhook\n\u001b[32m    591\u001b[39m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[32m    592\u001b[39m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/subprocess.py:148\u001b[39m, in \u001b[36mCalledProcessError.__str__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCommand \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m died with unknown signal \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % (\n\u001b[32m    146\u001b[39m                 \u001b[38;5;28mself\u001b[39m.cmd, -\u001b[38;5;28mself\u001b[39m.returncode)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33;43m\"\u001b[39;49m\u001b[33;43mCommand \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m returned non-zero exit status \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturncode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: %d format: a real number is required, not NoneType"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "%d format: a real number is required, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3413\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3409\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3411\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3413\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3414\u001b[39m     )\n\u001b[32m   3416\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3474\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3470\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3471\u001b[39m             \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3472\u001b[39m             stb = traceback.format_exception(etype, evalue, tb)\n\u001b[32m-> \u001b[39m\u001b[32m3474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mename\u001b[39m\u001b[33m\"\u001b[39m: etype.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mevalue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mtraceback\u001b[39m\u001b[33m\"\u001b[39m: stb}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/demos/lib/python3.12/subprocess.py:148\u001b[39m, in \u001b[36mCalledProcessError.__str__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCommand \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m died with unknown signal \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % (\n\u001b[32m    146\u001b[39m                 \u001b[38;5;28mself\u001b[39m.cmd, -\u001b[38;5;28mself\u001b[39m.returncode)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33;43m\"\u001b[39;49m\u001b[33;43mCommand \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m returned non-zero exit status \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturncode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: %d format: a real number is required, not NoneType"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export OADMET_NO_RICH_LOGGING=1\n",
    "\n",
    "openadmet anvil --recipe-path anvil_lgbm.yaml --output-dir lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3873eae",
   "metadata": {},
   "source": [
    "The outputs of the Anvil workflow are in `/anvil_training`:  \n",
    "- `/data` folder includes the split data, saved as `.csv`\n",
    "- `/recipe_components` folder contains the inputs from the `2.1_anvil_lgbm.yaml` file split by section\n",
    "- `cross_validation_metrics.json` is the cross validation metrics of the model saved as a `.json` file\n",
    "- `model.json` is the model's hyperparameters saved as a `.json` file\n",
    "- `regression_metrics.json` is the regression metrics saved as a `.json` file\n",
    "- `model.pkl` is the trained model saved as `.pkl` which can be loaded and used for predictions elsewhere\n",
    "- `cross_validation_regplot.png` is a plot of the cross validation metrics of the model\n",
    "- `anvil_recipe.yaml` is a copy of the input `.yaml`\n",
    "\n",
    "Here are the results of above trained LGBM model:\n",
    "\n",
    "<img src=\"lgbm/cross_validation_regplot.png\" alt=\"LGBM model results\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66e72e2",
   "metadata": {},
   "source": [
    "## Training a Deep Learning model: ChemProp\n",
    "\n",
    "Here is a `YAML` file (`anvil_chemprop.yaml`) for training OpenADMET's ChemProp model. We are using the same ChEMBL CYP3A4 dataset. Be sure to note the different fields required for deep learning.\n",
    "\n",
    "```yaml\n",
    "# This spection specifies the input data\n",
    "data:\n",
    "  # Specify the dataset file\n",
    "  resource: ../01_Data_Curation/processed_data/processed_CYP3A4_inhibition.csv\n",
    "  type: intake\n",
    "  input_col: OPENADMET_CANONICAL_SMILES\n",
    "  # Specify each (1+) of the target columns, or the column that you're trying to predict\n",
    "  target_cols:\n",
    "  - OPENADMET_LOGAC50\n",
    "\n",
    "\n",
    "# Additional metadata\n",
    "metadata:\n",
    "  authors: Your Name\n",
    "  email: youremail@mail.com\n",
    "  biotargets:\n",
    "  - CYP3A4\n",
    "  build_number: 0\n",
    "  description: basic regression using a ChemProp multitask task model\n",
    "  driver: pytorch\n",
    "  name: chemprop_pchembl\n",
    "  tag: chemprop-PXR-chembl\n",
    "  tags:\n",
    "  - openadmet\n",
    "  - test\n",
    "  version: v1\n",
    "\n",
    "# Section specifying training procedure\n",
    "procedure:\n",
    "  # Featurization specification\n",
    "  feat:\n",
    "    # Using the ChemPropFeaturizer (for ChemProp model)\n",
    "    # See openadmet.models.features\n",
    "    type: ChemPropFeaturizer\n",
    "    # No parameters passed\n",
    "    params: {}\n",
    "  \n",
    "  # Model specification\n",
    "  model:\n",
    "    # Indicate model type\n",
    "    # See openadmet.models.architecture\n",
    "    type: ChemPropModel\n",
    "    # Specify model parameters\n",
    "    params:\n",
    "      depth: 4\n",
    "      ffn_hidden_dim: 1024\n",
    "      ffn_hidden_num_layers: 4\n",
    "      message_hidden_dim: 2048\n",
    "      dropout: 0.2\n",
    "      batch_norm: True\n",
    "      messages: bond\n",
    "      n_tasks: 1 # Number of tasks should match the number of target columns\n",
    "      from_chemeleon: False\n",
    "\n",
    "  # Specify data splits\n",
    "  split:\n",
    "    # Specify how data will be split\n",
    "    # See openadmet.models.split\n",
    "    type: ShuffleSplitter\n",
    "    # Specify split parameters\n",
    "    params:\n",
    "      random_state: 42\n",
    "      train_size: 0.7\n",
    "      val_size: 0.1\n",
    "      test_size: 0.2\n",
    "    \n",
    "  # Specify training configuration\n",
    "  train:\n",
    "    # Specify the trainer, here LightningTrainer as ChemProp is a PyTorch Lightning model\n",
    "    # See openadmet.models.trainer\n",
    "    type: LightningTrainer\n",
    "    # Specify model parameters\n",
    "    params:\n",
    "      accelerator: gpu\n",
    "      early_stopping: true\n",
    "      early_stopping_patience: 10\n",
    "      early_stopping_mode: min\n",
    "      early_stopping_min_delta: 0.001\n",
    "      max_epochs: 50\n",
    "      monitor_metric: val_loss\n",
    "      use_wandb: false\n",
    "      wandb_project: demos # Specify wandb project name according to guidelines\n",
    "\n",
    "# Section specifying report generation\n",
    "report:\n",
    "  # Configure evaluation\n",
    "  eval:\n",
    "  # Generate regression metrics\n",
    "  - type: RegressionMetrics\n",
    "    params: {}\n",
    "  # Generate regression plots & do cross validation\n",
    "  - type: PytorchLightningRepeatedKFoldCrossValidation\n",
    "    params:\n",
    "      axes_labels:\n",
    "      - True LogAC50\n",
    "      - Predicted LogAC50\n",
    "      n_repeats: 5\n",
    "      n_splits: 5\n",
    "      random_state: 42\n",
    "      pXC50: true\n",
    "      title: True vs Predicted LogAC50 on test set\n",
    "```\n",
    "\n",
    "The command is\n",
    "```\n",
    "openadmet anvil --recipe-path anvil_chemprop.yaml --output-dir chemprop\n",
    "```\n",
    "We recommend training deep learning models on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0046aa-e3b8-4aa5-b568-5f19b3fc2de2",
   "metadata": {},
   "source": [
    "The results of a pre-trained version we provide are shown here\n",
    "\n",
    "\n",
    "<img src=\"./chemprop/cross_validation_regplot.png\" alt=\"ChemProp model results\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df8f65",
   "metadata": {},
   "source": [
    "## Training a Multitask Deep Learning Model: ChemProp\n",
    "\n",
    "There may be instances where you will want to train a model to predict compound activity on multiple protein targets.\n",
    "\n",
    "For example, you may have endpoints that share a biochemical pathway such that activity on one is thought to be somewhat correlated to the other. \n",
    "\n",
    "It would thus be useful to train a multitask model on multiple targets. The `YAML` file example shown below is `anvil_multitask.yaml`.\n",
    "\n",
    "```yaml\n",
    "# Section specifying input data\n",
    "data:\n",
    "  # Specify the dataset file, can be S3 path etc.\n",
    "  resource:  ../01_Data_Curation/processed_data/multitask.parquet\n",
    "  # must be intake\n",
    "  type: intake\n",
    "  # Specify input column containing SMILES\n",
    "  input_col: OPENADMET_CANONICAL_SMILES\n",
    "  # Specify whether or not to drop NaN data rows\n",
    "  dropna: False\n",
    "  # Specify each (1+) of the target columns\n",
    "  target_cols:\n",
    "  - OPENADMET_LOGAC50_cyp2j2\n",
    "  - OPENADMET_LOGAC50_cyp3a4\n",
    "  - OPENADMET_LOGAC50_cyp1a2\n",
    "  - OPENADMET_LOGAC50_pxr\n",
    "  - OPENADMET_LOGAC50_cyp2d6\n",
    "  - OPENADMET_LOGAC50_cyp2c9\n",
    "  - OPENADMET_LOGAC50_ahr\n",
    "\n",
    "# Additional metadata\n",
    "metadata:\n",
    "  authors: Your Name\n",
    "  email: youremail@mail.com\n",
    "  biotargets:\n",
    "  - CYP3A4\n",
    "  - CYP2J2\n",
    "  - CYP1A2\n",
    "  - CYP2D6\n",
    "  - CYP2C9\n",
    "  - PXR\n",
    "  - AHR\n",
    "  build_number: 0\n",
    "  description: basic regression using a ChemProp multitask task model\n",
    "  driver: pytorch\n",
    "  name: chemprop_pchembl\n",
    "  tag: chemprop\n",
    "  tags:\n",
    "  - openadmet\n",
    "  - test\n",
    "  - chemprop\n",
    "  version: v1\n",
    "\n",
    "# Section specifying training procedure\n",
    "procedure:\n",
    "  # Featurization specification\n",
    "  feat:\n",
    "    # Using the ChemPropFeaturizer (for ChemProp model)\n",
    "    # See openadmet.models.features\n",
    "    type: ChemPropFeaturizer\n",
    "    # No parameters passed\n",
    "    params: {}\n",
    "  \n",
    "  # Model specification\n",
    "  model:\n",
    "    # Indicate model type\n",
    "    # See openadmet.models.architecture\n",
    "    type: ChemPropModel\n",
    "    # Specify model parameters\n",
    "    params:\n",
    "      depth: 4\n",
    "      ffn_hidden_dim: 1024\n",
    "      ffn_hidden_num_layers: 4\n",
    "      message_hidden_dim: 2048\n",
    "      dropout: 0.2\n",
    "      batch_norm: True\n",
    "      messages: bond\n",
    "      n_tasks: 7 # Number of tasks should match the number of target columns\n",
    "      from_chemeleon: False\n",
    "\n",
    "  # Specify data splits\n",
    "  split:\n",
    "    # Specify how data will be split, can be ShuffleSplitter, ScaffoldSplitter, etc.\n",
    "    # See openadmet.models.split\n",
    "    type: ShuffleSplitter\n",
    "    # Specify split parameters\n",
    "    params:\n",
    "      random_state: 42\n",
    "      train_size: 0.7\n",
    "      val_size: 0.1\n",
    "      test_size: 0.2\n",
    "    \n",
    "  # Specify training configuration\n",
    "  train:\n",
    "    # Specify the trainer, here LightningTrainer as ChemProp is a PyTorch Lightning model\n",
    "    # See openadmet.models.trainer\n",
    "    type: LightningTrainer\n",
    "    # Specify model parameters\n",
    "    params:\n",
    "      accelerator: gpu\n",
    "      early_stopping: true\n",
    "      early_stopping_patience: 10\n",
    "      early_stopping_mode: min\n",
    "      early_stopping_min_delta: 0.001\n",
    "      max_epochs: 50\n",
    "      monitor_metric: val_loss\n",
    "      use_wandb: false\n",
    "      wandb_project: demos # Specify wandb project name according to guidelines\n",
    "\n",
    "# Section specifying report generation\n",
    "report:\n",
    "  # Configure evaluation\n",
    "  eval:\n",
    "  # Generate regression metrics\n",
    "  - type: RegressionMetrics\n",
    "    params: {}\n",
    "  # Generate regression plots & do cross validation\n",
    "  - type: PytorchLightningRepeatedKFoldCrossValidation\n",
    "    params:\n",
    "      axes_labels:\n",
    "      - True LogAC50\n",
    "      - Predicted LogAC50\n",
    "      n_repeats: 5\n",
    "      n_splits: 5\n",
    "      random_state: 42\n",
    "      pXC50: true\n",
    "      title: Multitask True vs Predicted LogAC50 on test set\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da263b6-d2ac-4d10-8f58-76473f5e83b9",
   "metadata": {},
   "source": [
    "The results of a pre-trained version we provide are shown here\n",
    "\n",
    "\n",
    "<img src=\"./multitask/cross_validation_regplot_OPENADMET_LOGAC50_cyp3a4.png\" alt=\"ChemProp model results\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e5073",
   "metadata": {},
   "source": [
    "We will examine the full results of these models in `03_Model_Comparison`.\n",
    "\n",
    "Congrats! You now know how to train models with the Anvil workflow. Explore our [model catalog](https://github.com/OpenADMET/openadmet-models/tree/main/openadmet/models) for other model architectures and featurizers.\n",
    "\n",
    "\n",
    "**Now let's compare the performance of our models!**\n",
    "\n",
    "~ End of `02_Training_Models` ~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
