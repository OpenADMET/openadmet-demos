{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6fae82",
   "metadata": {},
   "source": [
    "# 3.0 Comparing Models\n",
    "### After Training your Models, What's Next?\n",
    "After training multiple models with Anvil, you will want to compare the performance across models in a robust way. We closely follow the guidlines laid out in [this paper](https://chemrxiv.org/engage/chemrxiv/article-details/672a91bd7be152b1d01a926b). Consider the below decision chart for helping figure out which models to compare:\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src=\"comparison_guidelines.png\" alt=\"Model comparison\" width=\"500\"/>.  \n",
    "</div>\n",
    "\n",
    "### Requirements\n",
    "For this demo, you will need:\n",
    "1. At least 2 models trained with the Anvil workflow.\n",
    "2. All models trained with same cross validation splits, e.g. 5 splits x 5 repeats\n",
    "## Overview\n",
    "This notebook will walk you through how to use the OpenADMET CLI to evaluate models that have been trained with the Anvil workflow. In this particular demo, we will compare the models we trained in `02_Training_Models.ipynb`.\n",
    "\n",
    "## Use Anvil to Compare Models\n",
    "As with training models with Anvil, comparing models is also a simple command with the following arguments:\n",
    "```bash\n",
    "    openadmet compare \\\n",
    "        --model-stats <path-1/cross_validation_metrics.json> \\ # this is the path to the cross_validation_metrics.json file output by anvil of your first model\n",
    "        --model-tag <a-tag-to-label-your-trained-model-1> \\ # this can be any moniker that is distinguishable for you\n",
    "        --task-name <name-of-task-1> \\ # this is the name of your target_cols from the anvil recipe.yaml\n",
    "        \\\n",
    "\n",
    "        --model-stats <path-2/cross_validation_metrics.json> \\ # corresponding info for your second model\n",
    "        --model-tag <a-tag-to-label-your-trained-model-2> \\\n",
    "        --task-name <name-of-task-2> \\\n",
    "\n",
    "        ... repeat this set of arguments for as many models as you want to compare\n",
    "\n",
    "\n",
    "        --output-dir <path-to-output-plots> \\ # this is an existing directory for your plot to export to\n",
    "        --report <whether-or-not-to-write-pdf-report>\n",
    "```\n",
    "**IMPORTANT NOTE** You can only compare models that have the same number of cross validation folds, e.g. a model with `5 splits x 2 repeats` can only be compared to another model that is also cross validated with `5 splits x 2 repeats`.\n",
    "For this demo, this command is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cynthiaxu/miniconda3/envs/demos/lib/python3.12/site-packages/openadmet/models/comparison/posthoc.py:476: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '***' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  significance[(hsd.pvalue < self.sig_levels[2]) & (hsd.pvalue >= 0)] = \"***\"\n",
      "/Users/cynthiaxu/miniconda3/envs/demos/lib/python3.12/site-packages/openadmet/models/comparison/posthoc.py:477: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '**' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  significance[\n",
      "/Users/cynthiaxu/miniconda3/envs/demos/lib/python3.12/site-packages/openadmet/models/comparison/posthoc.py:476: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '***' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  significance[(hsd.pvalue < self.sig_levels[2]) & (hsd.pvalue >= 0)] = \"***\"\n",
      "/Users/cynthiaxu/miniconda3/envs/demos/lib/python3.12/site-packages/openadmet/models/comparison/posthoc.py:476: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '***' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  significance[(hsd.pvalue < self.sig_levels[2]) & (hsd.pvalue >= 0)] = \"***\"\n",
      "/Users/cynthiaxu/miniconda3/envs/demos/lib/python3.12/site-packages/openadmet/models/comparison/posthoc.py:477: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '**' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  significance[\n",
      "/Users/cynthiaxu/miniconda3/envs/demos/lib/python3.12/site-packages/openadmet/models/comparison/posthoc.py:483: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  significance[(hsd.pvalue >= self.sig_levels[0])] = \"\"\n",
      "/Users/cynthiaxu/miniconda3/envs/demos/lib/python3.12/site-packages/openadmet/models/comparison/posthoc.py:477: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '**' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  significance[\n",
      "/Users/cynthiaxu/miniconda3/envs/demos/lib/python3.12/site-packages/openadmet/models/comparison/posthoc.py:483: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  significance[(hsd.pvalue >= self.sig_levels[0])] = \"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's test results\n",
      "-------------------------\n",
      "+------------+-----------+------------+----------+-------------+\n",
      "|        mse |       mae |         r2 |     ktau |   spearmanr |\n",
      "|------------+-----------+------------+----------+-------------|\n",
      "| 5.34346    | 2.76955   | 6.26403    | 1.71125  |    1.02614  |\n",
      "| 0.00685875 | 0.0693782 | 0.00310412 | 0.187905 |    0.363568 |\n",
      "+------------+-----------+------------+----------+-------------+\n",
      "\n",
      "Tukey's HSD results\n",
      "-------------------------\n",
      "+-----------------------------+-----------+------------+-------------+-------------+\n",
      "| method                      | metric    |      value |   errorbars |     p-value |\n",
      "|-----------------------------+-----------+------------+-------------+-------------|\n",
      "| lgbm-chemprop               | mse       | -0.0950442 |   0.0480257 | 3.14253e-05 |\n",
      "| lgbm-chemprop_multitask     | mse       | -0.0244335 |   0.0480257 | 0.446793    |\n",
      "| chemprop-chemprop_multitask | mse       |  0.0706107 |   0.0480257 | 0.0021588   |\n",
      "| lgbm-chemprop               | mae       | -0.0559771 |   0.0284019 | 3.37982e-05 |\n",
      "| lgbm-chemprop_multitask     | mae       | -0.0100893 |   0.0284019 | 0.673245    |\n",
      "| chemprop-chemprop_multitask | mae       |  0.0458878 |   0.0284019 | 0.000694214 |\n",
      "| lgbm-chemprop               | r2        |  0.146625  |   0.0771146 | 6.25715e-05 |\n",
      "| lgbm-chemprop_multitask     | r2        |  0.0255316 |   0.0771146 | 0.708926    |\n",
      "| chemprop-chemprop_multitask | r2        | -0.121093  |   0.0771146 | 0.000996093 |\n",
      "| lgbm-chemprop               | ktau      |  0.0213658 |   0.0309269 | 0.230308    |\n",
      "| lgbm-chemprop_multitask     | ktau      | -0.0198805 |   0.0309269 | 0.279267    |\n",
      "| chemprop-chemprop_multitask | ktau      | -0.0412463 |   0.0309269 | 0.00587683  |\n",
      "| lgbm-chemprop               | spearmanr |  0.0270532 |   0.0355809 | 0.170473    |\n",
      "| lgbm-chemprop_multitask     | spearmanr | -0.0181248 |   0.0355809 | 0.445901    |\n",
      "| chemprop-chemprop_multitask | spearmanr | -0.045178  |   0.0355809 | 0.00917452  |\n",
      "+-----------------------------+-----------+------------+-------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "openadmet compare \\\n",
    "    --model-stats ../../02_Model_Training/lgbm/cross_validation_metrics.json \\\n",
    "    --model-tag lgbm \\\n",
    "    --task-name OPENADMET_LOGAC50 \\\n",
    "    --model-stats ../../02_Model_Training/chemprop/cross_validation_metrics.json \\\n",
    "    --model-tag chemprop \\\n",
    "    --task-name OPENADMET_LOGAC50 \\\n",
    "    --model-stats ../../02_Model_Training/multitask/cross_validation_metrics.json \\\n",
    "    --model-tag multitask \\\n",
    "    --task-name OPENADMET_LOGAC50_cyp3a4 \\\n",
    "    --output-dir model_comparisons/ \\\n",
    "    --report True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf35ff7",
   "metadata": {},
   "source": [
    "Now, in model comparisons, you should find these outputs:\n",
    "- `Levene.json` - file containing results of Levene test which assesses homogeneity of variances among groups\n",
    "- `Tukey_HSD.json` - file containing confidence intervals for Tukey HSD (honestly significant difference) test for pairwise comparisons between models\n",
    "- `anova.pdf` - ANOVA (analsyis of variance) plot showing whether each metric across all the compared models are statistically signficantly different; p-value ≤ 0.05\n",
    "- `mcs_plots.pdf`- multiple comparisons similarity plot where the color denotes effect size and asterisk annotations denote statistical significance\n",
    "- `mean_diffs.pdf`- plot of confidence intervals of the difference in mean performance between models; intervals that do not cross the zero line imply statistical significance\n",
    "- `normality_plots.pdf` - plots to show how normal the distribution of metrics are to check assumptions of parametric tests, e.g. ANOVA, etc.\n",
    "- `paired_plots.pdf` - plots to check pairwise relationships between metrics across the comparing models\n",
    "- `posthoc.pdf` - a file containing the tabulated Levene and Tukey HSD results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138d65b",
   "metadata": {},
   "source": [
    "### Interpreting the comparison plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1283cfb",
   "metadata": {},
   "source": [
    "✨✨✨✨✨✨✨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
