{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b549fd",
   "metadata": {},
   "source": [
    "# 4.0 Ensemble Model Training\n",
    "\n",
    "## Why Train an Ensemble of Models?\n",
    "\n",
    "For complex problems, like predicting ADMET profiles of compounds, where data is  it can be beneficial to increase the robustness and accuracy of model predictions by training an **ensemble** of models rather than relying on a single model.\n",
    "\n",
    "### Requirements\n",
    "As in `02_Training_Models.ipynb`, you will need:\n",
    "\n",
    "1. A dataset that has been processed with `01_Curate_ChEMBL_Data.ipynb`.  \n",
    "2. A `YAML` file with instructions for Anvil and specifically for ensemble model training. We will show you how to create this file in this notebook.\n",
    "\n",
    "## Overview\n",
    "This notebook will walk you through how to train an ensemble of models with the Anvil workflow with the same CYP3A4 data used in `02_Training_Models.ipynb`.\n",
    "\n",
    "## Create the YAML file\n",
    "As in `02_Training_Models.ipynb`, we will use a `YAML` file containing all the necessary information to train the ensemble. The only difference from the usual anvil recipe is the `ensemble` section.  \n",
    "\n",
    "In the below example, we will be training a **5-model** ensemble of `LGBM` regressors with the CYP3A4 ChEMBL data.  \n",
    "\n",
    "```yaml\n",
    "# This spection specifies the input data\n",
    "data:\n",
    "  # Specify the dataset file\n",
    "  resource: ../01_Data_Curation/processed_data/processed_CYP3A4_inhibition.csv\n",
    "  type: intake\n",
    "  input_col: OPENADMET_SMILES\n",
    "  # Specify each (1+) of the target columns, or the column that you're trying to predict\n",
    "  target_cols:\n",
    "  - OPENADMET_LOGAC50\n",
    "  dropna: true\n",
    "\n",
    "# Additional metadata\n",
    "metadata:\n",
    "  authors: Your Name\n",
    "  email: youremail@email.com\n",
    "  biotargets:\n",
    "  - CYP3A4\n",
    "  build_number: 0\n",
    "  description: basic regression using a LightGBM model\n",
    "  driver: sklearn\n",
    "  name: lgbm_pchembl\n",
    "  tag: openadmet-chembl\n",
    "  tags:\n",
    "  - openadmet\n",
    "  - test\n",
    "  - pchembl\n",
    "  version: v1\n",
    "\n",
    "# Section specifying training procedure\n",
    "procedure:\n",
    "# Featurization specification\n",
    "  feat:\n",
    "    # Using concatenated features, which combines multiple featurizers\n",
    "    # here we use DescriptorFeaturizer and FingerprintFeaturizer for 2D RDKit descriptors and ECFP4 fingerprints\n",
    "    # See openadmet.models.features \n",
    "    type: FeatureConcatenator\n",
    "    # Add parameters for the featurizer. Full description of the featurizer options are in Section 5.\n",
    "    params:\n",
    "      featurizers:\n",
    "        DescriptorFeaturizer:\n",
    "          descr_type: \"desc2d\"\n",
    "        FingerprintFeaturizer:\n",
    "          fp_type: \"ecfp:4\"\n",
    "  \n",
    "  # Model specification\n",
    "  model:\n",
    "    # Indicate model type\n",
    "    # See openadmet.models.architecture for all model types\n",
    "    type: LGBMRegressorModel\n",
    "    # Specify model parameters\n",
    "    params:\n",
    "      alpha: 0.005\n",
    "      learning_rate: 0.05\n",
    "      n_estimators: 500\n",
    "\n",
    "  # Ensemble specification\n",
    "  ensemble:\n",
    "    type: CommitteeRegressor\n",
    "    n_models: 5\n",
    "    calibration_method: scaling-factor\n",
    "\n",
    "  # Specify data splits\n",
    "  split:\n",
    "    # Specify how data will be split\n",
    "    # See openadmet.models.split\n",
    "    type: ShuffleSplitter\n",
    "    # Specify split parameters\n",
    "    params:\n",
    "      random_state: 42\n",
    "      train_size: 0.7\n",
    "      val_size: 0.1 # Validation set is needed for uncertainty calibration\n",
    "      test_size: 0.2 # If you want to compare tree-based models with Dl models later, the test sizes should match\n",
    "    \n",
    "  # Specify training configuration\n",
    "  train:\n",
    "    # Specify the trainer, here SKLearnBasicTrainer as model has an sklearn interface\n",
    "    # could also use SKLearnGridSearchTrainer for hyperparameter tuning\n",
    "    type: SKLearnBasicTrainer\n",
    "\n",
    "\n",
    "# Section specifying report generation\n",
    "report:\n",
    "  # Configure evaluation\n",
    "  eval:\n",
    "  # Generate regression metrics\n",
    "  - type: RegressionMetrics\n",
    "    params: {}\n",
    "  # Generate regression plots & do cross validation\n",
    "  - type: SKLearnRepeatedKFoldCrossValidation\n",
    "    params:\n",
    "      axes_labels:\n",
    "      - True pAC50\n",
    "      - Predicted pAC50\n",
    "      max_val: 10\n",
    "      min_val: 3\n",
    "      pXC50: true\n",
    "      n_splits: 5\n",
    "      n_repeats: 5\n",
    "      title: True vs Predicted pAC50 on test set\n",
    "  # Generate uncertainty metrics\n",
    "  - type: UncertaintyMetrics\n",
    "    params:\n",
    "      bins: 100\n",
    "      resolution: 99\n",
    "      scaled: True\n",
    "  # Generate uncertainty calibration plot\n",
    "  - type: UncertaintyPlots\n",
    "    params: {}\n",
    "```\n",
    "\n",
    "The command for running anvil is exactly the same as it was before!\n",
    "\n",
    "```bash\n",
    "    openadmet anvil --recipe-path anvil_ensemble.yaml --output-dir ensemble\n",
    "```\n",
    "\n",
    "**We highly recommend training on GPU for ensemble models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87381d98",
   "metadata": {},
   "source": [
    "~ End of `04_Ensemble_Model_Training` ~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
